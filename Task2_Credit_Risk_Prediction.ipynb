{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae419a09",
   "metadata": {},
   "source": [
    "\n",
    "# Task 2 — Credit Risk Prediction\n",
    "\n",
    "**Objective:** Predict whether a loan applicant will default.  \n",
    "**Dataset:** Kaggle *Loan Prediction* (train/test CSVs).  \n",
    "**Notes:** This notebook assumes you've downloaded the dataset from Kaggle and placed `train.csv` (and optionally `test.csv`) under `./data/loan/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbf30d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287171c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "data_dir = Path('data/loan')\n",
    "train_csv = None\n",
    "for p in [data_dir/'train.csv', Path('../data/loan/train.csv'), Path('/mnt/data/devhub_ds_tasks/data/loan/train.csv')]:\n",
    "    if p.exists():\n",
    "        train_csv = p\n",
    "        break\n",
    "\n",
    "if train_csv is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"Please download the Kaggle 'Loan Prediction' dataset and place train.csv at ./data/loan/train.csv\"\n",
    "    )\n",
    "\n",
    "df = pd.read_csv(train_csv)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0b91d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Basic EDA\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "display(df.head())\n",
    "display(df.isna().sum().sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d208e0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Target & features\n",
    "# Common versions of this dataset use 'Loan_Status' (Y/N) as target.\n",
    "target_col = 'Loan_Status' if 'Loan_Status' in df.columns else None\n",
    "if target_col is None:\n",
    "    raise KeyError(\"Could not find 'Loan_Status' column. Please confirm the dataset version.\")\n",
    "\n",
    "X = df.drop(columns=[target_col, 'Loan_ID'] if 'Loan_ID' in df.columns else [target_col])\n",
    "y = (df[target_col].astype(str).str.upper().map({'Y':1, 'N':0})).astype(int)\n",
    "\n",
    "# Identify types\n",
    "numeric = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "# Preprocess\n",
    "pre = ColumnTransformer([\n",
    "    ('num', SimpleImputer(strategy='median'), numeric),\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]), categorical)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750816dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model: Logistic Regression (baseline)\n",
    "log_reg = Pipeline([\n",
    "    ('pre', pre),\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Alternative: Decision Tree\n",
    "tree = Pipeline([\n",
    "    ('pre', pre),\n",
    "    ('clf', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "log_reg.fit(X_train, y_train)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "preds_lr = log_reg.predict(X_test)\n",
    "preds_tr = tree.predict(X_test)\n",
    "\n",
    "acc_lr = accuracy_score(y_test, preds_lr)\n",
    "acc_tr = accuracy_score(y_test, preds_tr)\n",
    "print(f\"Accuracy — Logistic Regression: {acc_lr:.3f}\")\n",
    "print(f\"Accuracy — Decision Tree     : {acc_tr:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56de7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Confusion matrix (best model)\n",
    "best_preds = preds_lr if acc_lr >= acc_tr else preds_tr\n",
    "best_name = \"Logistic Regression\" if acc_lr >= acc_tr else \"Decision Tree\"\n",
    "cm = confusion_matrix(y_test, best_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.title(f\"Confusion Matrix — {best_name}\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report —\", best_name)\n",
    "print(classification_report(y_test, best_preds, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46855bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Brief conclusion (edit as needed)\n",
    "print(\"\"\"\n",
    "• We handled missing values via median (numeric) and most_frequent (categorical), then OHE for categoricals.\n",
    "• Baseline models show above-chance accuracy. Tune hyperparameters (grid search) and add cross-validation for improvements.\n",
    "• Consider feature scaling for algorithms like SVM/LogReg and try ensemble models (RandomForest, XGBoost).\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
